
import cv2
from openvino.inference_engine import IENetwork, IECore


def openvino_inference(img, opt):

    model_bin = os.path.splitext(opt.xml_model)[0] + ".bin"

    # ------------- 1. Plugin initialization for specified device and load extensions library if specified -------------
    ie = IECore()
    if opt.cpu_extension and 'CPU' in opt.openvino_device:
        ie.add_extension(opt.cpu_extension, "CPU")

    # -------------------- 2. Reading the IR generated by the Model Optimizer (.xml and .bin files) --------------------
    net = IENetwork(model=opt.xml_model, weights=model_bin)

    # ---------------------------------- 3. Load CPU extension for support specific layer ------------------------------
    if "CPU" in opt.openvino_device:
        supported_layers = ie.query_network(net, "CPU")
        not_supported_layers = [l for l in net.layers.keys() if l not in supported_layers]
        if len(not_supported_layers) != 0:
            print("Following layers are not supported by the plugin for specified device {}:\n {}".
                      format(opt.openvino_device, ', '.join(not_supported_layers)))
            print("Please try to specify cpu extensions library path in sample's command line parameters using -l "
                      "or --cpu_extension command line argument")
            sys.exit(1)

    assert len(net.inputs.keys()) == 1, "Sample supports only YOLO V3 based single input topologies"

    # ---------------------------------------------- 4. Preparing inputs -----------------------------------------------
    input_blob = next(iter(net.inputs))

    #  Defaulf batch_size is 1
    net.batch_size = 1

    # Read and pre-process input images
    n, c, h, w = net.inputs[input_blob].shape
    # print(n,c,h,w)
    is_async_mode = False

    # ----------------------------------------- 5. Loading model to the plugin -----------------------------------------
    exec_net = ie.load_network(network=net, num_requests=2, device_name=opt.openvino_device)

    cur_request_id = 0
    next_request_id = 1

    # ----------------------------------------------- 6. Doing inference -----------------------------------------------
    print("Starting inference...")
    print("To close the application, press 'CTRL+C' here or switch to the output window and press ESC key")
    print("To switch between sync/async modes, press TAB key in the output window")


    if is_async_mode:
        request_id = next_request_id
        # in_frame = letterbox(frame, (w, h))
    else:
        request_id = cur_request_id
        # in_frame = letterbox(frame, (w, h))

    # in_frame0 = in_frame
    # resize input_frame to network size
    # in_frame = in_frame.transpose((2, 0, 1))  # Change data layout from HWC to CHW
    img = img.reshape((n, c, h, w))

    # Start inference
    exec_net.start_async(request_id=request_id, inputs={input_blob: img})

    # Collecting object detection results
    if exec_net.requests[cur_request_id].wait(-1) == 0:
       openvino_out = exec_net.requests[cur_request_id].outputs

    return openvino_out